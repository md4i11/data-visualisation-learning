{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b697d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Ensure tensorflow is available in the notebook kernel\n",
    "%pip install tensorflow -q\n",
    "\n",
    "import os\n",
    "# import pickle\n",
    "# import random\n",
    "# import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score, roc_auc_score, classification_report\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.optimizers import Adam\n",
    "# from keras import optimizers, metrics, layers, models, applications\n",
    "# from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import load_model, Model, Sequential\n",
    "# # from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, GlobalAveragePooling2D, PReLU, Dropout, BatchNormalization\n",
    "# from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3469629e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (94, 224, 224, 3),\n",
      " Labels shape: (94,)\n"
     ]
    }
   ],
   "source": [
    "# in this section, i have iterated through all the images in the covid and normal folder\n",
    "# the images have been labelled if they are covid or normal, covid = 1 and normal = 0\n",
    "# converted those images to RGB, then resize them and make them consistent size \n",
    "# turned those images into numpy arrays and printed their shape \n",
    "folder_path = r'C:\\_Dhruti\\Projects\\data-visualisation-learning\\data\\raw'\n",
    "types = ['covid', 'normal']\n",
    "\n",
    "data = [] \n",
    "labels = []\n",
    "\n",
    "for t in types:\n",
    "    path = os.path.join(folder_path, t)\n",
    "    label = 1 if t == 'covid' else 0\n",
    "    for img_name in os.listdir(path):\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        # print (img_path) \n",
    "        img = Image.open(img_path).convert('RGB')           # ensures 3 channels because not everytime there wil be RGB \n",
    "        img = img.resize((224, 224))                        # resizing to make it consistent \n",
    "        img_array = np.array(img) / 255.0                   # converting to array and normalizing\n",
    "        data.append(img_array)                              # saving the image data\n",
    "        labels.append(label)                                # saving the label \n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print (f\"Data shape: {data.shape},\\n Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c22c8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape:  (75, 224, 224, 3)\n",
      "test data shape:  (19, 224, 224, 3)\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# in this section, i have broken the data into 2 sets - train set and test set using\n",
    "# the train_test_split function from sklearn\n",
    "# and then convert the labels to categorise into 2 classes - covid and normal using to_categorical function from keras \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size=0.2, random_state=42, stratify=labels)  # previous line was to split the dataset into train and test sets \n",
    "print(\"training data shape: \", X_train.shape)\n",
    "print(\"test data shape: \", X_test.shape)\n",
    "\n",
    "y_train_category = to_categorical(Y_train, num_classes=2)\n",
    "y_test_category = to_categorical(Y_test, num_classes=2)\n",
    "\n",
    "print(y_train_category[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a31e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1c1f6a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\_Dhruti\\Projects\\data-visualisation-learning\\data-v\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    \n",
    "    # Conv2D is the convolutional block; there are 32 filters #applied 3x3 to scan he image to the input shape 224x2224x3\n",
    "    # relu makes the convolutional layer output non-negative and non-linear\n",
    "    # input shape is from teh shape of data/images i have\n",
    "    # First convolutional block\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n",
    "\n",
    "    MaxPooling2D((2,2)),\n",
    "    # MaxPooling2D is the pooling layer which reduces the spatial dimensions of the feature maps by half \n",
    "    # halving the dimensions helps to reduce the number of parameters and computation in the model, which can help prevent overfitting and improve generalization\n",
    "    # overfitting model means that the model performs well on the training data but poorly on unseen data\n",
    "    # first convolutional block is the first layer of the model which extracts low-level features from the input images, such as edges and textures.\n",
    "\n",
    "    # second and third convolutional blocks are deeper layers that extract more complex features, \n",
    "    # such as shapes and patterns, which are important for distinguishing between covid and normal images.\n",
    "    # Second convolutional block\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    # Third convolutional block\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    # Flatten and fully connected layers\n",
    "    Flatten(),\n",
    "    # flatten function will convert the 3D feature maps into a 1D vector, which can be fed into the fully connected layers for classification.\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # prevents overfitting\n",
    "\n",
    "    # Dense and Dropout \n",
    "    # Dense means fully connected to flatten features - 128 neurons \n",
    "    # Dropout means randomly disables 50% of neurons during training -- prevents overfitting \n",
    "    # memorizing the training data instead of learning general patterns, which can lead to poor performance on unseen data.\n",
    "    \n",
    "    Dense(1, activation='sigmoid')  # binary classification\n",
    "    # this dense has 1 layer which means it will output single value (binary classification) \n",
    "    # and sigmoid is outputting 1 or 0 which determines COVID or NORMAL \n",
    "    # sigmoid --> >= 0.5 then classified as COVID else NORMAL\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b323d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',   # for 2-class problems\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0545c4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 0.6133 - loss: 0.6970 - val_accuracy: 0.7368 - val_loss: 0.5589\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.7333 - loss: 0.5710 - val_accuracy: 0.7368 - val_loss: 0.5264\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.7600 - loss: 0.5180 - val_accuracy: 0.7368 - val_loss: 0.4745\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.7333 - loss: 0.4608 - val_accuracy: 0.7368 - val_loss: 0.4304\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.7467 - loss: 0.4819 - val_accuracy: 0.7368 - val_loss: 0.3658\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.8133 - loss: 0.4018 - val_accuracy: 0.8947 - val_loss: 0.3031\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.9067 - loss: 0.3185 - val_accuracy: 1.0000 - val_loss: 0.2359\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.9067 - loss: 0.2772 - val_accuracy: 1.0000 - val_loss: 0.1760\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.9467 - loss: 0.2264 - val_accuracy: 1.0000 - val_loss: 0.1344\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.9467 - loss: 0.1984 - val_accuracy: 1.0000 - val_loss: 0.1005\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, Y_train,           # training data\n",
    "    validation_data=(X_test, Y_test),\n",
    "    epochs=10,                  # start small; increase later\n",
    "    batch_size=16               # adjust based on memory\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "72319b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1005\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-v (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
