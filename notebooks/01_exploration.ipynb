{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3b697d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Ensure tensorflow is available in the notebook kernel\n",
    "%pip install tensorflow -q\n",
    "\n",
    "import os\n",
    "# import pickle\n",
    "# import random\n",
    "# import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score, roc_auc_score, classification_report\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.optimizers import Adam\n",
    "# from keras import optimizers, metrics, layers, models, applications\n",
    "# from keras.callbacks import ReduceLROnPlateau\n",
    "# from keras.models import load_model, Model, Sequential\n",
    "# # from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, GlobalAveragePooling2D, PReLU, Dropout, BatchNormalization\n",
    "# from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3469629e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (94, 224, 224, 3),\n",
      " Labels shape: (94,)\n"
     ]
    }
   ],
   "source": [
    "# in this section, i have iterated through all the images in the covid and normal folder\n",
    "# the images have been labelled if they are covid or normal, covid = 1 and normal = 0\n",
    "# converted those images to RGB, then resize them and make them consistent size \n",
    "# turned those images into numpy arrays and printed their shape \n",
    "folder_path = r'C:\\_Dhruti\\Projects\\data-visualisation-learning\\data\\raw'\n",
    "types = ['covid', 'normal']\n",
    "\n",
    "data = [] \n",
    "labels = []\n",
    "\n",
    "for t in types:\n",
    "    path = os.path.join(folder_path, t)\n",
    "    label = 1 if t == 'covid' else 0\n",
    "    for img_name in os.listdir(path):\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        # print (img_path) \n",
    "        img = Image.open(img_path).convert('RGB')           # ensures 3 channels because not everytime there wil be RGB \n",
    "        img = img.resize((224, 224))                        # resizing to make it consistent \n",
    "        img_array = np.array(img) / 255.0                   # converting to array and normalizing\n",
    "        data.append(img_array)                              # saving the image data\n",
    "        labels.append(label)                                # saving the label \n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print (f\"Data shape: {data.shape},\\n Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c22c8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape:  (75, 224, 224, 3)\n",
      "test data shape:  (19, 224, 224, 3)\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# in this section, i have broken the data into 2 sets - train set and test set using\n",
    "# the train_test_split function from sklearn\n",
    "# and then convert the labels to categorise into 2 classes - covid and normal using to_categorical function from keras \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size=0.2, random_state=42, stratify=labels)  # previous line was to split the dataset into train and test sets \n",
    "print(\"training data shape: \", X_train.shape)\n",
    "print(\"test data shape: \", X_test.shape)\n",
    "\n",
    "y_train_category = to_categorical(Y_train, num_classes=2)\n",
    "y_test_category = to_categorical(Y_test, num_classes=2)\n",
    "\n",
    "print(y_train_category[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c1f6a2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m      1\u001b[39m model = Sequential([\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# First convolutional block\u001b[39;00m\n\u001b[32m      3\u001b[39m     Conv2D(\u001b[32m32\u001b[39m, (\u001b[32m3\u001b[39m,\u001b[32m3\u001b[39m), activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m, input_shape=(\u001b[32m224\u001b[39m,\u001b[32m224\u001b[39m,\u001b[32m3\u001b[39m)),\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     Dense(\u001b[32m1\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33msigmoid\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# binary classification\u001b[39;00m\n\u001b[32m     19\u001b[39m ])\n\u001b[32m     21\u001b[39m model.compile(\n\u001b[32m     22\u001b[39m     optimizer=Adam(learning_rate=\u001b[32m0.0001\u001b[39m),\n\u001b[32m     23\u001b[39m     loss=\u001b[33m'\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m'\u001b[39m,   \u001b[38;5;66;03m# for 2-class problems\u001b[39;00m\n\u001b[32m     24\u001b[39m     metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     25\u001b[39m )\n\u001b[32m     27\u001b[39m history = model.fit(\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     X_train, \u001b[43my_train\u001b[49m,           \u001b[38;5;66;03m# training data\u001b[39;00m\n\u001b[32m     29\u001b[39m     validation_data=(X_test, y_test),\n\u001b[32m     30\u001b[39m     epochs=\u001b[32m10\u001b[39m,                  \u001b[38;5;66;03m# start small; increase later\u001b[39;00m\n\u001b[32m     31\u001b[39m     batch_size=\u001b[32m16\u001b[39m               \u001b[38;5;66;03m# adjust based on memory\u001b[39;00m\n\u001b[32m     32\u001b[39m )\n\u001b[32m     34\u001b[39m loss, accuracy = model.evaluate(X_test, y_test)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    # First convolutional block\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    # Second convolutional block\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    # Third convolutional block\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    # Flatten and fully connected layers\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # prevents overfitting\n",
    "    Dense(1, activation='sigmoid')  # binary classification\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',   # for 2-class problems\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,           # training data\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=10,                  # start small; increase later\n",
    "    batch_size=16               # adjust based on memory\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-v (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
