{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b697d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Ensure tensorflow is available in the notebook kernel\n",
    "%pip install tensorflow -q\n",
    "\n",
    "import os\n",
    "# import pickle\n",
    "# import random\n",
    "# import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score, roc_auc_score, classification_report\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.optimizers import Adam\n",
    "# from keras import optimizers, metrics, layers, models, applications\n",
    "# from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import load_model, Model, Sequential\n",
    "# # from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, GlobalAveragePooling2D, PReLU, Dropout, BatchNormalization\n",
    "# from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3469629e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (94, 224, 224, 3),\n",
      " Labels shape: (94,)\n"
     ]
    }
   ],
   "source": [
    "# in this section, i have iterated through all the images in the covid and normal folder\n",
    "# the images have been labelled if they are covid or normal, covid = 1 and normal = 0\n",
    "# converted those images to RGB, then resize them and make them consistent size \n",
    "# turned those images into numpy arrays and printed their shape \n",
    "folder_path = r'C:\\_Dhruti\\Projects\\data-visualisation-learning\\data\\raw'\n",
    "types = ['covid', 'normal']\n",
    "\n",
    "data = [] \n",
    "labels = []\n",
    "\n",
    "for t in types:\n",
    "    path = os.path.join(folder_path, t)\n",
    "    label = 1 if t == 'covid' else 0\n",
    "    for img_name in os.listdir(path):\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        # print (img_path) \n",
    "        img = Image.open(img_path).convert('RGB')           # ensures 3 channels because not everytime there wil be RGB \n",
    "        img = img.resize((224, 224))                        # resizing to make it consistent \n",
    "        img_array = np.array(img) / 255.0                   # converting to array and normalizing\n",
    "        data.append(img_array)                              # saving the image data\n",
    "        labels.append(label)                                # saving the label \n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print (f\"Data shape: {data.shape},\\n Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c22c8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape:  (75, 224, 224, 3)\n",
      "test data shape:  (19, 224, 224, 3)\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# in this section, i have broken the data into 2 sets - train set and test set using\n",
    "# the train_test_split function from sklearn\n",
    "# and then convert the labels to categorise into 2 classes - covid and normal using to_categorical function from keras \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size=0.2, random_state=42, stratify=labels)  # previous line was to split the dataset into train and test sets \n",
    "print(\"training data shape: \", X_train.shape)\n",
    "print(\"test data shape: \", X_test.shape)\n",
    "\n",
    "y_train_category = to_categorical(Y_train, num_classes=2)\n",
    "y_test_category = to_categorical(Y_test, num_classes=2)\n",
    "\n",
    "print(y_train_category[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d7cff",
   "metadata": {},
   "source": [
    "| Note                                  | Code Part                                     |\n",
    "| ------------------------------------- | --------------------------------------------- |\n",
    "| 2–3 Conv2D layers → ReLU → MaxPooling | The three Conv2D + MaxPooling2D blocks        |\n",
    "| Flatten → Dense → Output              | `Flatten() → Dense(128) → Dropout → Dense(1)` |\n",
    "| Binary classification                 | `Dense(1, activation='sigmoid')`              |\n",
    "| Start simple                          | This is a small, beginner-friendly CNN        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f6a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\_Dhruti\\Projects\\data-visualisation-learning\\data-v\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# model architecture is defined \n",
    "model = Sequential([\n",
    "    \n",
    "    # Conv2D is the convolutional block; there are 32 filters #applied 3x3 to scan he image to the input shape 224x2224x3\n",
    "    # relu makes the convolutional layer output non-negative and non-linear\n",
    "    # input shape is from teh shape of data/images i have\n",
    "    # First convolutional block\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n",
    "\n",
    "    MaxPooling2D((2,2)),\n",
    "    # MaxPooling2D is the pooling layer which reduces the spatial dimensions of the feature maps by half \n",
    "    # halving the dimensions helps to reduce the number of parameters and computation in the model, which can help prevent overfitting and improve generalization\n",
    "    # overfitting model means that the model performs well on the training data but poorly on unseen data\n",
    "    # first convolutional block is the first layer of the model which extracts low-level features from the input images, such as edges and textures.\n",
    "\n",
    "    # second and third convolutional blocks are deeper layers that extract more complex features, \n",
    "    # such as shapes and patterns, which are important for distinguishing between covid and normal images.\n",
    "    # Second convolutional block\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    # Third convolutional block\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    # Flatten and fully connected layers\n",
    "    Flatten(),\n",
    "    # flatten function will convert the 3D feature maps into a 1D vector, which can be fed into the fully connected layers for classification.\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # prevents overfitting\n",
    "    # Dense and Dropout \n",
    "    # Dense means fully connected to flatten features - 128 neurons \n",
    "    # Dropout means randomly disables 50% of neurons during training -- prevents overfitting \n",
    "    # memorizing the training data instead of learning general patterns, which can lead to poor performance on unseen data.\n",
    "\n",
    "    Dense(1, activation='sigmoid')  # binary classification\n",
    "    # this dense has 1 layer which means it will output single value (binary classification) \n",
    "    # and sigmoid is outputting 1 or 0 which determines COVID or NORMAL \n",
    "    # sigmoid --> >= 0.5 then classified as COVID else NORMAL\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b323d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how the model should learn \n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',   # for 2-class problems\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# this means how the model should learn \n",
    "# Adam in optimizer is the adaptive gradient optimizer \n",
    "# learning rate means how big the weight setup is, too big or too small will result in unstable or slow learning\n",
    "# loss function measures how wrong the moddel is \n",
    "# binary crossentropy is used for binary classification problems (for e.g. here covid or normal)\n",
    "# metrics is used to evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0545c4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 9.9582e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 5.1137e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 9.8753e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 5.3875e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.9867 - loss: 0.0167 - val_accuracy: 1.0000 - val_loss: 4.7345e-04\n"
     ]
    }
   ],
   "source": [
    "# how the model is trained \n",
    "history = model.fit(\n",
    "    X_train, Y_train,           # training data\n",
    "    validation_data=(X_test, Y_test),\n",
    "    epochs=10,                  # start small; increase later\n",
    "    batch_size=16               # adjust based on memory\n",
    ")\n",
    "# For each epoch, the model will take 16 images, make predictions, calculate loss, updates weight using adam\n",
    "# this repeats until all training images are used. \n",
    "# Validation_data means the model tests itself on unseen data\n",
    "# epochs means the model sees entire dataset 10 times \n",
    "# batch_size means feeding 16 images at a time, otherwise too muchh memory will be consumed and it might crash  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72319b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 4.7345e-04\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3917fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    \n",
    "    # Add batch dimension (VERY IMPORTANT)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "\n",
    "def predict_image(image_path):\n",
    "    processed_image = preprocess_image(image_path)\n",
    "    \n",
    "    prediction = model.predict(processed_image)\n",
    "    \n",
    "    probability = prediction[0][0]\n",
    "    \n",
    "    if probability >= 0.5:\n",
    "        print(f\"Prediction: COVID ({probability*100:.2f}% confidence)\")\n",
    "    else:\n",
    "        print(f\"Prediction: NORMAL ({(1-probability)*100:.2f}% confidence)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90dd80ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Prediction: COVID (100.00% confidence)\n"
     ]
    }
   ],
   "source": [
    "predict_image(r\"C:\\_Dhruti\\Projects\\data-visualisation-learning\\data\\processed\\23E99E2E-447C-46E5-8EB2-D35D12473C39.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-v (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
